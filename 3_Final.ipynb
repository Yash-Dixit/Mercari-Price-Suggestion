{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSkJrAvtmxAr"
   },
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9X__N5RNIHlz",
    "outputId": "061a24b6-9a27-450c-9001-2a07769a78b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "import scipy\n",
    "import nltk\n",
    "import pickle\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import hstack\n",
    "from tensorflow.keras.models import model_from_json\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJ6Mcwtcm7tp"
   },
   "source": [
    "# 2. Predefined Functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bKACspp5nAQY"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/My\\ Drive/mercari\\ data/brands.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/main_cats.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/main_sub_cats.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/sub_cats.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/item_condition_id_vectorizer.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/number_of_colours_vectorizer.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/brand_name_codes_vectorizer.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/main_category_codes_vectorizer.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/main_sub_category_codes_vectorizer.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/sub_category_codes_vectorizer.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/feature_ml.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/finalized_ridge.sav /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/finalized_lgbm.sav /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/feature_mlp.pkl /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/mlp_model.json /content\n",
    "!cp /content/drive/My\\ Drive/mercari\\ data/mlp_model.h5 /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sjimen9YOM_i"
   },
   "outputs": [],
   "source": [
    "def fill_brands_na(train_brand_name, all_text, all_text_no_punc):\n",
    "  '''\n",
    "      This function imputes the missing values for brands in the given dataset\n",
    "  '''\n",
    "  merge_brands_more_than_1_word, \\\n",
    "  brands_with_1_word, \\\n",
    "  brands_with_1_word_junk_extra, \\\n",
    "  brands_with_1_word_junk = pickle.load(open('brands.pkl', 'rb'))\n",
    "\n",
    "  # **********IMPUTATION STARTS HERE**********\n",
    "  \n",
    "  for counter in range(len(train_brand_name)):\n",
    "    #====================================\n",
    "    # STEP 1\n",
    "    #====================================\n",
    "\n",
    "    # merge_brands_more_than_1_word --- text with punctuation\n",
    "    if train_brand_name[counter] == \"Unknown Brand.\":\n",
    "      count = 0\n",
    "      for brand, preprocessed_brands in merge_brands_more_than_1_word.items():\n",
    "        for preprocessed_brand in preprocessed_brands:\n",
    "          if preprocessed_brand in all_text[counter]:\n",
    "            train_brand_name[counter] = brand\n",
    "            count = 1\n",
    "            break\n",
    "        if count>0:\n",
    "          break\n",
    "        \n",
    "    if train_brand_name[counter] != \"Unknown Brand.\":\n",
    "      continue\n",
    "\n",
    "    # merge_brands_more_than_1_word --- text with no punctuation\n",
    "    if train_brand_name[counter] == \"Unknown Brand.\":\n",
    "      count = 0\n",
    "      for brand, preprocessed_brands in merge_brands_more_than_1_word.items():\n",
    "        for preprocessed_brand in preprocessed_brands:\n",
    "          if preprocessed_brand in all_text_no_punc[counter]:\n",
    "            train_brand_name[counter] = brand\n",
    "            count = 1\n",
    "            break\n",
    "        if count>0:\n",
    "          break\n",
    "\n",
    "    if train_brand_name[counter] != \"Unknown Brand.\":\n",
    "      continue\n",
    "\n",
    "    #====================================\n",
    "    # STEP 2\n",
    "    #====================================\n",
    "\n",
    "    # brands_with_1_word --- text with punctuation\n",
    "    if train_brand_name[counter] == \"Unknown Brand.\":\n",
    "      count = 0\n",
    "      for brand, preprocessed_brands in brands_with_1_word.items():\n",
    "        for preprocessed_brand in preprocessed_brands:\n",
    "          if preprocessed_brand in all_text[counter].split():\n",
    "            train_brand_name[counter] = brand\n",
    "            count = 1\n",
    "            break\n",
    "        if count>0:\n",
    "          break\n",
    "\n",
    "    if train_brand_name[counter] != \"Unknown Brand.\":\n",
    "      continue\n",
    "\n",
    "    #brands_with_1_word --- text with no punctuation\n",
    "    if train_brand_name[counter] == \"Unknown Brand.\":\n",
    "      count = 0\n",
    "      for brand, preprocessed_brands in brands_with_1_word.items():\n",
    "        for preprocessed_brand in preprocessed_brands:\n",
    "          if preprocessed_brand in all_text_no_punc[counter].split():\n",
    "            train_brand_name[counter] = brand\n",
    "            count = 1\n",
    "            break\n",
    "        if count>0:\n",
    "          break\n",
    "\n",
    "    if train_brand_name[counter] != \"Unknown Brand.\":\n",
    "      continue\n",
    "\n",
    "    #====================================\n",
    "    # STEP 3\n",
    "    #====================================\n",
    "\n",
    "    #brands_with_1_word_junk_extra --- text with punctuation\n",
    "    if train_brand_name[counter] == \"Unknown Brand.\":\n",
    "      count = 0\n",
    "      for brand, preprocessed_brands in brands_with_1_word_junk_extra.items():\n",
    "        for preprocessed_brand in preprocessed_brands:\n",
    "          if preprocessed_brand in all_text[counter]:\n",
    "            train_brand_name[counter] = brand\n",
    "            count = 1\n",
    "            break\n",
    "        if count>0:\n",
    "          break\n",
    "        \n",
    "    if train_brand_name[counter] != \"Unknown Brand.\":\n",
    "      continue\n",
    "\n",
    "    # brands_with_1_word_junk_extra --- text with no punctuation\n",
    "    if train_brand_name[counter] == \"Unknown Brand.\":\n",
    "      count = 0\n",
    "      for brand, preprocessed_brands in brands_with_1_word_junk_extra.items():\n",
    "        for preprocessed_brand in preprocessed_brands:\n",
    "          if preprocessed_brand in all_text_no_punc[counter]:\n",
    "            train_brand_name[counter] = brand\n",
    "            count = 1\n",
    "            break\n",
    "        if count>0:\n",
    "          break\n",
    "\n",
    "    if train_brand_name[counter] != \"Unknown Brand.\":\n",
    "      continue\n",
    "\n",
    "    #====================================\n",
    "    # STEP 4\n",
    "    #====================================\n",
    "\n",
    "    # brands_with_1_word_junk --- text with punctuation\n",
    "    if train_brand_name[counter] == \"Unknown Brand.\":\n",
    "      count = 0\n",
    "      for brand, preprocessed_brands in brands_with_1_word_junk.items():\n",
    "        for preprocessed_brand in preprocessed_brands:\n",
    "          if preprocessed_brand in all_text[counter].split():\n",
    "            train_brand_name[counter] = brand\n",
    "            count = 1\n",
    "            break\n",
    "        if count>0:\n",
    "          break\n",
    "\n",
    "    if train_brand_name[counter] != \"Unknown Brand.\":\n",
    "      continue\n",
    "\n",
    "    #brands_with_1_word_junk --- text with no punctuation\n",
    "    if train_brand_name[counter] == \"Unknown Brand.\":\n",
    "      count = 0\n",
    "      for brand, preprocessed_brands in brands_with_1_word_junk.items():\n",
    "        for preprocessed_brand in preprocessed_brands:\n",
    "          if preprocessed_brand in all_text_no_punc[counter].split():\n",
    "            train_brand_name[counter] = brand\n",
    "            count = 1\n",
    "            break\n",
    "        if count>0:\n",
    "          break\n",
    "\n",
    "  del merge_brands_more_than_1_word\n",
    "  del brands_with_1_word\n",
    "  del brands_with_1_word_junk_extra\n",
    "  del brands_with_1_word_junk\n",
    "\n",
    "  return train_brand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fKAgUD_rOsSX"
   },
   "outputs": [],
   "source": [
    "def brand_text(df):\n",
    "  '''\n",
    "  This function preprocesses the textual data present in the dataset\n",
    "  '''\n",
    "  \n",
    "  df[\"item_description\"] = df[\"item_description\"].fillna(value=\"No description yet.\")\n",
    "  all_text = list(df['name']+\" \"+df['item_description'])\n",
    "\n",
    "  #define punctuation\n",
    "  all_text_no_punc = []\n",
    "  punctuations = '!()-[]{};:\\'\\\"\\,<>./?@#$%^&*_~©®™'\n",
    "  for i in range(len(all_text)):\n",
    "    no_punct = \"\"\n",
    "    for char in all_text[i]:\n",
    "      if char not in punctuations:\n",
    "        no_punct = no_punct + char\n",
    "      else:\n",
    "        no_punct = no_punct + \" \"\n",
    "    #Appending the text version with no punctuations\n",
    "    all_text_no_punc.append((\" \".join(no_punct.split())).lower())\n",
    "    #Appending the text version with punctuations\n",
    "    all_text[i] = all_text[i].lower()\n",
    "\n",
    "  return all_text, all_text_no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eIAKc2ZORWa-"
   },
   "outputs": [],
   "source": [
    "def fill_cats(cat_list, cat_string, unique_categories, all_text):\n",
    "  for i in range(len(cat_list)):\n",
    "    if cat_list[i] == cat_string:\n",
    "      count = 0\n",
    "      for k,v in unique_categories.items():\n",
    "        for cat in v:\n",
    "          if cat in all_text[i]:\n",
    "            cat_list[i] = k\n",
    "            count = 1\n",
    "            break\n",
    "        if count>0:\n",
    "          break\n",
    "  return cat_list\n",
    "\n",
    "def fill_cats_na(X,all_text):\n",
    "  main_categories = pickle.load(open('main_cats.pkl', 'rb'))\n",
    "  main_sub_categories = pickle.load(open('main_sub_cats.pkl', 'rb'))\n",
    "  sub_categories = pickle.load(open('sub_cats.pkl', 'rb'))\n",
    "\n",
    "  # There are 3 categories per Category Name in the data.\n",
    "  # The format of the category is : main_category/main_sub_category/sub_category\n",
    "  # So I have created 3 lists to split them with respect to the punctuation '/'.\n",
    "  # This is the code to create lists of main and its sub-categories\n",
    "\n",
    "  categories = list(X['category_name'])\n",
    "  main_category = []\n",
    "  main_sub_category = []\n",
    "  sub_category = []\n",
    "\n",
    "  for i in categories:\n",
    "    if not i==\"Unknown Category.\":\n",
    "      temp = i.split('/')\n",
    "      main_category.append(temp[0])\n",
    "      main_sub_category.append(temp[1])\n",
    "      sub_category.append(temp[2])\n",
    "    else:\n",
    "      main_category.append(\"Unknown Main-Category.\")\n",
    "      main_sub_category.append(\"Unknown Main-Sub-Category.\")\n",
    "      sub_category.append(\"Unknown Sub-Category.\")\n",
    "\n",
    "  main_category = fill_cats(main_category,\"Unknown Main-Category.\",main_categories,all_text)\n",
    "  del main_categories\n",
    "  main_sub_category = fill_cats(main_sub_category,\"Unknown Main-Sub-Category.\",main_sub_categories,all_text)\n",
    "  del main_sub_categories\n",
    "  sub_category = fill_cats(sub_category,\"Unknown Sub-Category.\",sub_categories,all_text)\n",
    "  del sub_categories\n",
    "\n",
    "  X['main_category'] = main_category\n",
    "  del main_category\n",
    "  X['main_sub_category'] = main_sub_category\n",
    "  del main_sub_category\n",
    "  X['sub_category'] = sub_category\n",
    "  del sub_category\n",
    "  del X['category_name']\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IRVi7FQpWwSP"
   },
   "outputs": [],
   "source": [
    "def fill_colours(X,all_text):\n",
    "  colours = [\"black\",\n",
    "           \"grey\",\n",
    "           \"white\",\n",
    "           \"beige\",\n",
    "           \"red\",\n",
    "           \"pink\",\n",
    "           \"purple\",\n",
    "           \"blue\",\n",
    "           \"green\",\n",
    "           \"yellow\",\n",
    "           \"orange\",\n",
    "           \"brown\",\n",
    "           \"gold\",\n",
    "           \"silver\"]\n",
    "\n",
    "  # Initializing a list containing the number of colours present in the text\n",
    "  number_of_colours = []\n",
    "\n",
    "  # Initializing a dictionary where - \n",
    "  # keys : The colours\n",
    "  # values : lists containing whether the colour is present or not\n",
    "  colours_dictionary = {}\n",
    "\n",
    "  number_of_colours = list(np.zeros(len(X[\"name\"]),np.int))\n",
    "\n",
    "  for colour in colours:\n",
    "    temp = []\n",
    "    counter = 0\n",
    "    for a in all_text:\n",
    "      if colour in a:\n",
    "        temp.append(1)\n",
    "        number_of_colours[counter] = number_of_colours[counter] + 1\n",
    "      else:\n",
    "        temp.append(0)\n",
    "      counter = counter +1\n",
    "    colours_dictionary[colour] = temp\n",
    "\n",
    "  for k,v in colours_dictionary.items():\n",
    "    X[k] = v\n",
    "  X[\"number_of_colours\"] = number_of_colours\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_j9T6a7VaIa1"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(all_text):\n",
    "  '''\n",
    "  This function preprocesses the item description and name of the datasets\n",
    "  '''\n",
    "\n",
    "  for i in range(len(all_text)):\n",
    "    #Preprocessing the words with apostrophes and new line characters as well\n",
    "    all_text[i] = re.sub(r\"won't\", \"will not\", all_text[i])\n",
    "    all_text[i] = re.sub(r\"can\\'t\", \"can not\", all_text[i])\n",
    "    all_text[i] = re.sub(r\"n\\'t\", \" not\", all_text[i])\n",
    "    all_text[i] = re.sub(r\"\\'re\", \" are\", all_text[i])\n",
    "    all_text[i] = re.sub(r\"\\'s\", \" is\", all_text[i])\n",
    "    all_text[i] = re.sub(r\"\\'d\", \" would\", all_text[i])\n",
    "    all_text[i] = re.sub(r\"\\'ll\", \" will\", all_text[i])\n",
    "    all_text[i] = re.sub(r\"\\'t\", \" not\", all_text[i])\n",
    "    all_text[i] = re.sub(r\"\\'ve\", \" have\", all_text[i])\n",
    "    all_text[i] = re.sub(r\"\\'m\", \" am\", all_text[i])\n",
    "    all_text[i] = all_text[i].replace('\\\\r', ' ')\n",
    "    all_text[i] = all_text[i].replace('\\\\n', ' ')\n",
    "    all_text[i] = all_text[i].replace('\\\\\"', ' ')\n",
    "    #Getting rid of unnecessary spaces\n",
    "    #all_text[i] = ' '.join(e.lower() for e in all_text[i].split() if e.lower() not in stopwords)\n",
    "    #Keeping only the alphanumeric characters and discarding the rest\n",
    "    all_text[i] = re.sub('[^A-Za-z0-9 ]', ' ', all_text[i])\n",
    "    #Getting rid of unnecessary spaces\n",
    "    #all_text[i] = ' '.join(e.lower() for e in all_text[i].split() if e.lower() not in stopwords)\n",
    "    all_text[i] = ' '.join(e.lower() for e in all_text[i].split())\n",
    "    # Converting \"24ml\" to \"24 ml\" or even \"2v2\" to '2 v 2' or many combinations as well\n",
    "    all_text[i] = re.sub('(?<=[A-Za-z])(?=[0-9])|(?<=[0-9])(?=[A-Za-z])',' ', all_text[i])\n",
    "    \n",
    "    #The code below lemmatizes the text wherein inherited texts of a word in substituted with the parent word.\n",
    "    #For example, go, gone, went and goes will be substituted with the parent word go.\n",
    "    # I have lemmatized both nouns as well as verbs for that matter\n",
    "    \n",
    "    # n denotes \"NOUN\" in \"pos\"\n",
    "    all_text[i] = ' '.join(lemmatizer.lemmatize(i, pos =\"n\") for i in all_text[i].split())\n",
    "    # v denotes \"VERB\" in \"pos\"\n",
    "    all_text[i] = ' '.join(lemmatizer.lemmatize(i, pos =\"v\") for i in all_text[i].split())\n",
    "  \n",
    "  return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YD-MwM9fhtbf"
   },
   "outputs": [],
   "source": [
    "def rmsle_score(actual, predicted, shape):\n",
    "  if shape>1:\n",
    "    return np.sqrt(np.nansum(np.square(np.log(predicted+1) - np.log(actual+1)))/float(len(actual)))\n",
    "  else:\n",
    "    return np.sqrt(np.nansum(np.square(np.log(predicted+1) - np.log(actual+1)))/float(1.0))\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    return tf.py_function(rmsle_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4tJLyXKpJzH"
   },
   "source": [
    "# 3. Function_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "q-rW58OwYKUD"
   },
   "outputs": [],
   "source": [
    "def function_1(X):\n",
    "  #Fill NaN values\n",
    "  X['brand_name'] = X['brand_name'].fillna(\"Unknown Brand.\")\n",
    "  X[\"item_description\"] = X[\"item_description\"].fillna(value=\"No description yet.\")\n",
    "  all_text, all_text_no_punc = brand_text(X)\n",
    "  X['brand_name'] = fill_brands_na(list(X['brand_name']),all_text, all_text_no_punc)\n",
    "  del all_text_no_punc\n",
    "\n",
    "  X['category_name'] = X['category_name'].fillna(value=\"Unknown Category.\")\n",
    "  X = fill_cats_na(X,all_text)\n",
    "  X = fill_colours(X,all_text)\n",
    "\n",
    "  item_desc_len = X[\"item_description\"].str.len() \n",
    "  X[\"item_desc_len_octa\"] = np.power(item_desc_len,0.125)\n",
    "  del item_desc_len\n",
    "  item_name_len = X[\"name\"].str.len()\n",
    "  X[\"item_name_len_sqrt\"] = np.sqrt(max(item_name_len+1)-item_name_len)\n",
    "  del item_name_len\n",
    "\n",
    "  # Creating a boolean column where 1 stands for [rm] is present in the description and 0 for the ones which don't have it.\n",
    "  item_rm = []\n",
    "  price_1 = []\n",
    "  price_0 = []\n",
    "\n",
    "  for i in range(len(list(X[\"item_description\"]))):\n",
    "    if '[rm]' in list(X[\"item_description\"])[i]:\n",
    "      item_rm.append(1)\n",
    "    else:\n",
    "      item_rm.append(0)\n",
    "      \n",
    "  X[\"Item_desc_[rm]_flag\"] = item_rm\n",
    "\n",
    "  # Creating a boolean column where 1 stands for [rm] is present in the description and 0 for the ones which don't have it.\n",
    "  item_rm = []\n",
    "  price_1 = []\n",
    "  price_0 = []\n",
    "  # Replacing NULL values with a dummy string\n",
    "\n",
    "  for i in range(len(list(X[\"name\"]))):\n",
    "    if '[rm]' in list(X[\"name\"])[i]:\n",
    "      item_rm.append(1)\n",
    "    else:\n",
    "      item_rm.append(0)\n",
    "\n",
    "  X[\"Name_[rm]_flag\"] = item_rm\n",
    "  del item_rm, price_1, price_0\n",
    "  X['preprocessed_text'] = preprocess_text(all_text)\n",
    "  del X['name'],X['item_description']\n",
    "\n",
    "  column = list(X['item_condition_id'])\n",
    "\n",
    "  for i in range(len(column)):\n",
    "    if column[i]==1:\n",
    "      column[i] = 'a'\n",
    "    elif column[i]==2:\n",
    "      column[i] = 'b'\n",
    "    elif column[i]==3:\n",
    "      column[i] = 'c'\n",
    "    elif column[i]==4:\n",
    "      column[i] = 'd'\n",
    "    else:\n",
    "      column[i] = 'e'\n",
    "  X['item_condition_id'] = column\n",
    "  del column\n",
    "\n",
    "  colours = scipy.sparse.csr_matrix(X[['black', 'grey', 'white', 'beige', \n",
    "                                               'red', 'pink', 'purple', 'blue', \n",
    "                                               'green', 'yellow', 'orange', 'brown', \n",
    "                                               'gold', 'silver','Item_desc_[rm]_flag', \n",
    "                                               'Name_[rm]_flag','item_desc_len_octa',\n",
    "                                               'item_name_len_sqrt','shipping']].values)\n",
    "  X['number_of_colours'] = X['number_of_colours'].astype('string')\n",
    "\n",
    "  item_condition_id_vectorizer = pickle.load(open('item_condition_id_vectorizer.pkl', 'rb'))\n",
    "  item_condition_id = item_condition_id_vectorizer.transform(X['item_condition_id'].values)\n",
    "  del item_condition_id_vectorizer\n",
    "  number_of_colours_vectorizer = pickle.load(open('number_of_colours_vectorizer.pkl', 'rb'))\n",
    "  number_of_colours = number_of_colours_vectorizer.transform(X['number_of_colours'].values)\n",
    "  del number_of_colours_vectorizer\n",
    "  brand_name_codes_vectorizer = pickle.load(open('brand_name_codes_vectorizer.pkl', 'rb'))\n",
    "  brand_name_codes = brand_name_codes_vectorizer.transform(X['brand_name'].values)\n",
    "  del brand_name_codes_vectorizer\n",
    "  main_category_codes_vectorizer = pickle.load(open('main_category_codes_vectorizer.pkl', 'rb'))\n",
    "  main_category_codes = main_category_codes_vectorizer.transform(X['main_category'].values)\n",
    "  del main_category_codes_vectorizer\n",
    "  main_sub_category_codes_vectorizer = pickle.load(open('main_sub_category_codes_vectorizer.pkl', 'rb'))\n",
    "  main_sub_category_codes = main_sub_category_codes_vectorizer.transform(X['main_sub_category'].values)\n",
    "  del main_sub_category_codes_vectorizer\n",
    "  sub_category_codes_vectorizer = pickle.load(open('sub_category_codes_vectorizer.pkl', 'rb'))\n",
    "  sub_category_codes = sub_category_codes_vectorizer.transform(X['sub_category'].values)\n",
    "  del sub_category_codes_vectorizer\n",
    "\n",
    "  final_data = hstack((item_condition_id,\n",
    "                       number_of_colours,\n",
    "                       brand_name_codes,\n",
    "                       main_category_codes,\n",
    "                       main_sub_category_codes,\n",
    "                       sub_category_codes,\n",
    "                       colours)).tocsr()\n",
    "\n",
    "  vectorizer_tfidf = pickle.load(open('feature_ml.pkl', 'rb'))\n",
    "  X_tfidf = vectorizer_tfidf.transform(X['preprocessed_text'])\n",
    "  del vectorizer_tfidf\n",
    "  X_ml = hstack((final_data,X_tfidf)).tocsr().astype('float32')\n",
    "  del X_tfidf\n",
    "\n",
    "  filename = 'finalized_ridge.sav'\n",
    "  loaded_model = pickle.load(open(filename, 'rb'))\n",
    "  result_1 = np.power(loaded_model.predict(X_ml),8)\n",
    "  filename = 'finalized_lgbm.sav'\n",
    "  loaded_model = pickle.load(open(filename, 'rb'))\n",
    "  result_2 = np.power(loaded_model.predict(X_ml),8)\n",
    "  del filename, loaded_model, X_ml\n",
    "\n",
    "  vectorizer_tfidf = pickle.load(open('feature_mlp.pkl', 'rb'))\n",
    "  X_tfidf = vectorizer_tfidf.transform(X['preprocessed_text'])\n",
    "  del vectorizer_tfidf\n",
    "  X = hstack((final_data,X_tfidf)).tocsr().astype('float32')  \n",
    "  del X_tfidf\n",
    "  # load json and create model\n",
    "  json_file = open(\"mlp_model.json\", 'r')\n",
    "  loaded_model_json = json_file.read()\n",
    "  json_file.close()\n",
    "  loaded_model = model_from_json(loaded_model_json)\n",
    "  # load weights into new model\n",
    "  loaded_model.load_weights(\"mlp_model.h5\")\n",
    "  # evaluate loaded model on test data\n",
    "  loaded_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0005),\n",
    "                loss=tf.keras.losses.MeanSquaredLogarithmicError(),\n",
    "                metrics = [rmsle])\n",
    "  result_3 = loaded_model.predict(X)\n",
    "  temp = []\n",
    "  for i in result_3:\n",
    "    for j in i:\n",
    "      temp.append(j)\n",
    "  result_3 = np.array(temp)\n",
    "  del X,temp\n",
    "  del json_file, loaded_model_json, loaded_model\n",
    "  result = 0.1*result_1 + 0.3*result_2 + 0.6*result_3\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TESL5JA2pge0"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/content/drive/My Drive/mercari data/train.csv\")\n",
    "del train['Unnamed: 0']\n",
    "price = train['price']\n",
    "del train['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jC3TztppRA_",
    "outputId": "fbd94858-9289-41a5-fa46-3bded345f75e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction of a single datapoint :  17.9521990680505\n",
      "CPU times: user 45.1 s, sys: 5.01 s, total: 50.1 s\n",
      "Wall time: 54.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"\\nPrediction of a single datapoint : \",function_1(train.iloc[[100000]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzdc8JFWm2iC",
    "outputId": "9cf1ecd8-bdea-413e-f86a-985d97854a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual value :  19.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nActual value : \",price[100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNAn_o7BVkS0",
    "outputId": "3b8b09ed-989c-43e8-ef4c-f7f06551ed92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction of multiple datapoints :  [15.723630098406936, 18.570566115572113, 52.86479554509762, 15.264150900916919, 5.83399450697756, 21.71636086295865, 4.815199382878427, 27.812748112236243, 12.526355985934131, 40.83565809653654, 23.976273918726065, 11.798341966552567, 70.39023727366724, 18.028935223261108, 159.65747718109853, 14.874348538856427, 9.22598601951536, 18.410751286832998, 38.79286853098621, 32.204333404556905, 12.92167618535252, 13.00588150244323, 13.47370397417669, 93.64618706360393, 22.893931985292532, 15.333665019684705, 40.23675827694302, 10.175613112682617, 28.041719062353394, 21.84405511758862, 61.25062932255206, 20.6276128345548, 19.251453468931544, 415.8492517752627, 16.91747060248891, 17.44840898314644, 22.95421783673899, 32.585048552199375, 46.903517965680756, 12.064505930975796, 12.285217612675948, 31.007755968968986, 30.232572299260063, 19.307005135219846, 16.406651707987827, 12.89070148000846, 16.27671647714855, 31.894940325798842, 29.403420566306817, 28.066269364781185, 19.116601927862224, 32.94759134326928, 15.433015591738268, 27.536019161839477, 12.901342229475109, 47.83666718719158, 40.76873181733714, 13.268396685941946, 65.56794027238502, 12.783134087150815, 24.022187762611946, 34.342358783750704, 12.984128732956519, 12.914723072151652, 15.638300648097946, 15.214657817773606, 10.415886807044012, 24.000549808177116, 36.27665099294499, 26.686119777219687, 3.90333867696502, 28.182096959679427, 16.87287945697982, 6.834681980125438, 7.049981289571047, 9.171481121750787, 8.259404804244156, 17.899761268244156, 11.230343940502602, 13.424270596773443, 3.7523846939202326, 14.343620473638559, 12.043545318237058, 12.178471465122733, 23.163881115375887, 15.311204735478135, 9.871545561174749, 25.721623761356696, 10.31523108422627, 52.832661557293505, 10.92876718630615, 26.63979362530566, 17.93855036731881, 25.872145889459517, 16.10473164564686, 26.290051483796184, 85.83943059568972, 29.664962645008092, 114.891691455209, 25.486221419917488, 10.253594067570118, 34.99448973509793, 20.561074725913475, 16.044759191662187, 14.761311068834974, 8.249178378208821, 32.75946342513936, 41.51028083328776, 17.335837327371078, 30.195300056329586, 15.130714132442648, 17.536751759855306, 18.15444490341169, 15.681402890984298, 30.78230569540051, 30.482221096498982, 8.449049555378096, 13.18713141972437, 12.430725075833891, 13.039074826890403, 11.290506372926433, 13.344273373552952, 19.119833370893677, 15.814765043322083, 12.285016633108587, 23.324675154838424, 12.398874290725843, 17.792676084628276, 35.20560106870845, 14.805216404148222, 14.62327327442586, 22.865253874828134, 10.900464301513134, 32.40504971000199, 111.00236444664117, 12.931595288856233, 7.383686908878692, 9.873381155384006, 15.210140285579076, 19.529706388321046, 14.725058194342068, 13.370905900343947, 19.271695824924077, 16.602317658268625, 46.06979803598134, 23.79512720660751, 16.376042335684023, 19.898514598359544, 20.71756509407419, 31.329543023178516, 39.517900000511, 10.564856743580593, 11.734014451648472, 7.155782317862838, 19.634514486756974, 11.408648423183811, 18.812622731542703, 19.926054109828712, 21.97500466041949, 13.774692836548542, 9.733413508583142, 14.219893003515296, 7.573217940941014, 17.446056018266408, 19.232684686611947, 30.481836720856293, 8.245139615673592, 13.492414502863003, 10.072313018147426, 23.9207843354563, 12.585905366513384, 9.133250995383639, 9.911019341583188, 13.44083962465152, 20.994556287449413, 7.60412858001297, 41.67884213674599, 14.625746449382362, 6.459979702624047, 15.093660298734381, 12.631693575757588, 14.639769228196313, 9.68019674134467, 3.905654757682478, 3.588764454652681, 56.983383129898115, 80.0450900982596, 12.299771853486316, 24.629495291365924, 19.53085545619132, 19.6676416067042, 9.115573397294998, 6.593062853845409, 11.605969202303587, 12.37580507644755, 10.133066016607614, 62.32321822423744, 22.925212733527715, 39.33442361747168, 25.279129964690753, 76.65471540128264, 28.667608342111457, 41.25884964014043, 16.513912598039614, 34.57490810936799, 12.529554215463907, 11.080002662884894, 25.2322451366309, 17.756722560539664, 33.02640144669829, 23.672508010279124, 12.108545408060994, 20.352120644392386, 14.824403383600462, 58.5115670690294, 18.270159202943184, 11.324229563594372, 9.357074521944151, 41.085424586449356, 31.513479710444578, 17.90469662457017, 11.398039843020285, 23.2763690408172, 188.04729637545677, 14.875521264479806, 45.889152445446925, 16.945917552727675, 10.726487433330806, 27.831634692778877, 19.314901337779354, 15.747593400473319, 20.826675808288456, 5.708581500764054, 16.20960159820587, 14.018821434445204, 25.34198530568619, 8.92106320993107, 21.73211861486839, 63.453097223784546, 39.74135497316345, 20.138999984109496, 12.690065304434537, 19.41517180636277, 13.822580897037762, 22.787039485819164, 18.324891180839217, 20.449490050417296, 17.267227703327837, 51.08995882580219, 18.09616239706395, 19.98738041646478, 29.0382859574988, 15.260981401967054, 22.368972304933603, 19.87431586252082, 12.408395602597968, 23.293506322655237, 9.472932011528219, 9.422232128293428, 22.4588634793618, 19.044104706352194, 17.113718714572794, 150.09449836166237, 22.618329005348745, 71.2963913406976, 10.868478143574599, 16.954284934629783, 21.294625648876494, 11.749301889525778, 18.55894803723804, 34.80053636234436, 18.604641598494602, 15.730898338256946, 6.7104541002997955, 17.88072952415437, 35.91015203704801, 11.640216402757126, 25.043566356184648, 5.964448890422357, 110.2779431969883, 22.020402656902544, 10.114244281385258, 24.343548041896156, 20.585261037649374, 24.8699305229922, 10.813737075448831, 24.52828387121408, 17.35952837030451, 14.854044965890822, 20.56870663824985, 26.42745947689928, 18.0915649897086, 31.324963958367036, 14.923333030932145, 19.256751967691606, 16.164734788621413, 16.74198608299804, 10.833292896794593, 24.785519261313937, 18.792630514123044, 11.353442217239937, 12.213288403448674, 18.244970833472962, 6.538596198980477, 46.29323331124191, 15.513754462995873, 9.264052733259671, 20.01395805831234, 14.311897374015214, 16.075199207014744, 16.3908002816519, 60.0488700188984, 17.36256243470197, 12.554387090025854, 15.913406111963097, 22.690967758790844, 20.00233730446293, 16.03342915499052, 9.676595659065836, 9.258081883457363, 15.714252858852532, 31.632414524415815, 18.397435699220146, 15.268967336877354, 7.560275399893682, 17.07312863728462, 26.740854452168403, 12.920171836269317, 8.83723206331793, 8.234630712000758, 16.234773920286322, 6.023053411525657, 18.328648454194038, 13.796933133251617, 19.30419460443421, 10.171101708758668, 32.77562241458082, 23.784720538431884, 32.31495272265468, 107.61861256922182, 8.144992661647075, 22.880307609584374, 20.102502013264896, 10.928199223800782, 11.376730154331753, 14.11646271220418, 21.40019843526037, 12.009258129450368, 16.43299312943306, 22.560231130611214, 21.328123537653813, 24.600872204222792, 18.901129941767284, 13.18885667982045, 12.691062163286691, 8.818526936795513, 19.345513613168382, 16.245883882722403, 89.36676013448628, 7.441540317801225, 9.579929383348327, 42.29906039445799, 13.644340339765261, 42.742487324053144, 41.74273644139732, 11.013061760348345, 13.569025132126162, 22.149934648960034, 14.521545640102932, 44.45365115807438, 19.68801163649875, 13.184196934853091, 6.897084086593267, 25.80133033001955, 15.210202823290938, 30.878681714407975, 25.958555518520747, 34.664798370341444, 14.829222278975532, 23.490871407464997, 9.269120882736505, 18.632876181227093, 10.523993141439274, 32.0855842261747, 13.62064954920494, 20.80679709807584, 35.68296300084408, 13.601865100991002, 20.823597582581016, 20.212893103496448, 37.40024852262583, 50.2997559229277, 10.362272643561798, 6.373756819191612, 34.78040928196147, 18.366918670019196, 10.526497777088005, 33.94609026671172, 25.545705853562133, 25.49538448900408, 34.79569936220099, 10.384185905883875, 13.875352082051506, 11.673684675021125, 23.29809092827179, 10.278877567315352, 5.6579302029913885, 19.912457343002448, 20.903560252535105, 19.665554808298197, 23.370008716608314, 21.37793949475237, 14.694021940857827, 26.2482895238633, 17.964637662144423, 18.634171300123032, 20.74321676573019, 65.77427639190881, 74.00937154146278, 17.28072828268075, 12.937140706848474, 14.165667258499838, 12.535897973792729, 22.79917573940301, 13.132303873239094, 153.4723030558012, 23.18406125728754, 9.634266688818336, 8.468370138861482, 5.181744697205025, 18.0752273589905, 27.438132929201316, 27.40897462559951, 17.049652152189537, 20.984244057167317, 8.827732283513717, 22.406468052382852, 24.786826938504895, 16.25316931636939, 21.48645539005535, 14.011393711591392, 22.17803782469723, 11.422029662589521, 30.524865847835997, 18.60458595046599, 14.827113303941939, 14.268760980764505, 15.57171500746032, 11.323679792343432, 11.506881828054212, 22.02071387931985, 7.461256310465167, 15.972068656760722, 44.238442716596424, 6.589056488854321, 25.44906235091393, 24.983804983043065, 14.767929701046434, 90.75742562737574, 16.65851620870928, 9.729383289386242, 19.610448919500833, 12.816122733133144, 20.345925047262412, 27.019613459158496, 12.726390750053582, 26.899998170185114, 8.203593743266774, 38.19411468070651, 10.171993770670934, 13.294845150597858, 30.867013867748305, 4.313037992294685, 23.739251786789083, 20.313022315966155, 10.399184866323212, 13.02556089930291, 11.027879717525265, 24.26933830510782, 25.670377670624354, 16.122177433923554, 20.620882379382948, 13.97655562596751, 24.979952546481478, 14.759466381240625, 12.974626335190456, 23.051217967661433, 20.359165716751683, 10.957477534122312, 14.137867442281852, 8.876130759182935, 11.636962490209052, 20.194837765138697, 30.22032837473791, 19.605121385679247, 6.558201876874577, 25.838912964094312, 35.96061658289126, 22.653983471787008, 16.876799350165015]\n",
      "CPU times: user 46.7 s, sys: 4.94 s, total: 51.6 s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(0)\n",
    "rn.seed(0)\n",
    "print(\"\\nPrediction of multiple datapoints : \",list(function_1(train.iloc[100000:100500])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1Kdqr1a7spv",
    "outputId": "17ce1b71-552a-4902-d90c-b787b14d8efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual values :  []\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nActual values : \",list(price[100500:100500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9hCoTPj4jqy"
   },
   "source": [
    "# 4. Function_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "U21sTnHTLs7f"
   },
   "outputs": [],
   "source": [
    "def function_1(X,y):\n",
    "  #Fill NaN values\n",
    "  shape = X.shape[0]\n",
    "  X['brand_name'] = X['brand_name'].fillna(\"Unknown Brand.\")\n",
    "  X[\"item_description\"] = X[\"item_description\"].fillna(value=\"No description yet.\")\n",
    "  all_text, all_text_no_punc = brand_text(X)\n",
    "  X['brand_name'] = fill_brands_na(list(X['brand_name']),all_text, all_text_no_punc)\n",
    "  del all_text_no_punc\n",
    "\n",
    "  X['category_name'] = X['category_name'].fillna(value=\"Unknown Category.\")\n",
    "  X = fill_cats_na(X,all_text)\n",
    "  X = fill_colours(X,all_text)\n",
    "\n",
    "  item_desc_len = X[\"item_description\"].str.len() \n",
    "  X[\"item_desc_len_octa\"] = np.power(item_desc_len,0.125)\n",
    "  del item_desc_len\n",
    "  item_name_len = X[\"name\"].str.len()\n",
    "  X[\"item_name_len_sqrt\"] = np.sqrt(max(item_name_len+1)-item_name_len)\n",
    "  del item_name_len\n",
    "\n",
    "  # Creating a boolean column where 1 stands for [rm] is present in the description and 0 for the ones which don't have it.\n",
    "  item_rm = []\n",
    "  price_1 = []\n",
    "  price_0 = []\n",
    "\n",
    "  for i in range(len(list(X[\"item_description\"]))):\n",
    "    if '[rm]' in list(X[\"item_description\"])[i]:\n",
    "      item_rm.append(1)\n",
    "    else:\n",
    "      item_rm.append(0)\n",
    "      \n",
    "  X[\"Item_desc_[rm]_flag\"] = item_rm\n",
    "\n",
    "  # Creating a boolean column where 1 stands for [rm] is present in the description and 0 for the ones which don't have it.\n",
    "  item_rm = []\n",
    "  price_1 = []\n",
    "  price_0 = []\n",
    "  # Replacing NULL values with a dummy string\n",
    "\n",
    "  for i in range(len(list(X[\"name\"]))):\n",
    "    if '[rm]' in list(X[\"name\"])[i]:\n",
    "      item_rm.append(1)\n",
    "    else:\n",
    "      item_rm.append(0)\n",
    "\n",
    "  X[\"Name_[rm]_flag\"] = item_rm\n",
    "  del item_rm, price_1, price_0\n",
    "  X['preprocessed_text'] = preprocess_text(all_text)\n",
    "  del X['name'],X['item_description']\n",
    "\n",
    "  column = list(X['item_condition_id'])\n",
    "\n",
    "  for i in range(len(column)):\n",
    "    if column[i]==1:\n",
    "      column[i] = 'a'\n",
    "    elif column[i]==2:\n",
    "      column[i] = 'b'\n",
    "    elif column[i]==3:\n",
    "      column[i] = 'c'\n",
    "    elif column[i]==4:\n",
    "      column[i] = 'd'\n",
    "    else:\n",
    "      column[i] = 'e'\n",
    "  X['item_condition_id'] = column\n",
    "  del column\n",
    "\n",
    "  colours = scipy.sparse.csr_matrix(X[['black', 'grey', 'white', 'beige', \n",
    "                                               'red', 'pink', 'purple', 'blue', \n",
    "                                               'green', 'yellow', 'orange', 'brown', \n",
    "                                               'gold', 'silver','Item_desc_[rm]_flag', \n",
    "                                               'Name_[rm]_flag','item_desc_len_octa',\n",
    "                                               'item_name_len_sqrt','shipping']].values)\n",
    "  X['number_of_colours'] = X['number_of_colours'].astype('string')\n",
    "\n",
    "  item_condition_id_vectorizer = pickle.load(open('item_condition_id_vectorizer.pkl', 'rb'))\n",
    "  item_condition_id = item_condition_id_vectorizer.transform(X['item_condition_id'].values)\n",
    "  del item_condition_id_vectorizer\n",
    "  number_of_colours_vectorizer = pickle.load(open('number_of_colours_vectorizer.pkl', 'rb'))\n",
    "  number_of_colours = number_of_colours_vectorizer.transform(X['number_of_colours'].values)\n",
    "  del number_of_colours_vectorizer\n",
    "  brand_name_codes_vectorizer = pickle.load(open('brand_name_codes_vectorizer.pkl', 'rb'))\n",
    "  brand_name_codes = brand_name_codes_vectorizer.transform(X['brand_name'].values)\n",
    "  del brand_name_codes_vectorizer\n",
    "  main_category_codes_vectorizer = pickle.load(open('main_category_codes_vectorizer.pkl', 'rb'))\n",
    "  main_category_codes = main_category_codes_vectorizer.transform(X['main_category'].values)\n",
    "  del main_category_codes_vectorizer\n",
    "  main_sub_category_codes_vectorizer = pickle.load(open('main_sub_category_codes_vectorizer.pkl', 'rb'))\n",
    "  main_sub_category_codes = main_sub_category_codes_vectorizer.transform(X['main_sub_category'].values)\n",
    "  del main_sub_category_codes_vectorizer\n",
    "  sub_category_codes_vectorizer = pickle.load(open('sub_category_codes_vectorizer.pkl', 'rb'))\n",
    "  sub_category_codes = sub_category_codes_vectorizer.transform(X['sub_category'].values)\n",
    "  del sub_category_codes_vectorizer\n",
    "\n",
    "  final_data = hstack((item_condition_id,\n",
    "                       number_of_colours,\n",
    "                       brand_name_codes,\n",
    "                       main_category_codes,\n",
    "                       main_sub_category_codes,\n",
    "                       sub_category_codes,\n",
    "                       colours)).tocsr()\n",
    "\n",
    "  vectorizer_tfidf = pickle.load(open('feature_ml.pkl', 'rb'))\n",
    "  X_tfidf = vectorizer_tfidf.transform(X['preprocessed_text'])\n",
    "  del vectorizer_tfidf\n",
    "  X_ml = hstack((final_data,X_tfidf)).tocsr().astype('float32')\n",
    "  del X_tfidf\n",
    "\n",
    "  filename = 'finalized_ridge.sav'\n",
    "  loaded_model = pickle.load(open(filename, 'rb'))\n",
    "  result_1 = np.power(loaded_model.predict(X_ml),8)\n",
    "  filename = 'finalized_lgbm.sav'\n",
    "  loaded_model = pickle.load(open(filename, 'rb'))\n",
    "  result_2 = np.power(loaded_model.predict(X_ml),8)\n",
    "  del filename, loaded_model, X_ml\n",
    "\n",
    "  vectorizer_tfidf = pickle.load(open('feature_mlp.pkl', 'rb'))\n",
    "  X_tfidf = vectorizer_tfidf.transform(X['preprocessed_text'])\n",
    "  del vectorizer_tfidf\n",
    "  X = hstack((final_data,X_tfidf)).tocsr().astype('float32')  \n",
    "  del X_tfidf\n",
    "  # load json and create model\n",
    "  json_file = open(\"mlp_model.json\", 'r')\n",
    "  loaded_model_json = json_file.read()\n",
    "  json_file.close()\n",
    "  loaded_model = model_from_json(loaded_model_json)\n",
    "  # load weights into new model\n",
    "  loaded_model.load_weights(\"mlp_model.h5\")\n",
    "  # evaluate loaded model on test data\n",
    "  loaded_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0005),\n",
    "                loss=tf.keras.losses.MeanSquaredLogarithmicError(),\n",
    "                metrics = [rmsle])\n",
    "  result_3 = loaded_model.predict(X)\n",
    "  temp = []\n",
    "  for i in result_3:\n",
    "    for j in i:\n",
    "      temp.append(j)\n",
    "  result_3 = np.array(temp)\n",
    "  del X,temp\n",
    "  del json_file, loaded_model_json, loaded_model\n",
    "  result = 0.1*result_1 + 0.3*result_2 + 0.6*result_3\n",
    "  score = rmsle_score(y,result,shape)\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSNYBytgLs3B",
    "outputId": "6bae85ce-a2a3-4010-ecb4-f0e3b8f0cde5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of a single datapoint :  0.053812403590904\n",
      "CPU times: user 44.1 s, sys: 3.99 s, total: 48.1 s\n",
      "Wall time: 55.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Score of a single datapoint : \",function_1(train.iloc[[100000]],price[100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vn14aTHkL8lt",
    "outputId": "3e0b722b-d4e5-444a-8f24-b6b9875cba7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score of multiple predictions :  0.3805815153812488\n",
      "CPU times: user 45.3 s, sys: 4.5 s, total: 49.8 s\n",
      "Wall time: 49.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"\\nScore of multiple predictions : \",function_1(train.iloc[100000:100500],price[100000:100500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRXGJW_b_ri4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YJ6Mcwtcm7tp"
   ],
   "name": "3_Productionisation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
